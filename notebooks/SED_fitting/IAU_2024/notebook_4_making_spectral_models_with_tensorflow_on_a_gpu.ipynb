{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbgqi7iKp14VHuUfKldEW8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FgpEJDtGAbAr"},"source":["This is just a quick notebook you can read, there's no tasks, but hopefully it might get you thinking about some useful things that can be done with GPUs for galaxy spectral analysis.\n","\n","One of the most interesting things about Colab is that it gives you free access to a GPU, as well as being pre-installed with Google's Tensorflow Python package for machine learning and GPU-accelerated computing.\n","\n","I've put together here a very quick example of how this might be useful for spectral fitting. This is just focused on making linear algebra happen more quickly on a GPU, rather than by applying machine learning methods, which is probably the most common application for Tensorflow.\n","\n","Before running anything in this notebook, go to Edit -> Notebook settings and check Hardware accelerator is set to GPU.\n","\n","On testing this notebook, I've found the results vary quite a lot when re-running, or after factory reseting the runtime. I guess this is partially because different hardware gets assigned to the notebook at different times. It might be worth using the options under Runtime to test a few different runtimes and repeated runs of the cells.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"id":"w2I6dQ___n4n","executionInfo":{"status":"ok","timestamp":1712067315929,"user_tz":-60,"elapsed":32897,"user":{"displayName":"Adam Carnall","userId":"09223017103187743113"}},"outputId":"71d2c3ef-6407-4030-f3f2-cf4e3d42e646"},"source":["# This first cell sets up the virtual machine with all the necessary software.\n","# There should be no need to edit this cell, just scroll down...\n","\n","# Install Bagpipes and python dependencies\n","!pip install bagpipes\n","\n","# Adjust the output height to avoid a huge wall of installation text\n","from IPython import display\n","display.Javascript(\"google.colab.output.setIframeHeight('100px');\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bagpipes\n","  Downloading bagpipes-1.1.1-py2.py3-none-any.whl (206.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.0/206.0 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bagpipes) (1.25.2)\n","Collecting corner (from bagpipes)\n","  Downloading corner-2.2.2-py3-none-any.whl (15 kB)\n","Collecting pymultinest>=2.11 (from bagpipes)\n","  Downloading pymultinest-2.12-py2.py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from bagpipes) (3.9.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from bagpipes) (1.5.3)\n","Requirement already satisfied: astropy in /usr/local/lib/python3.10/dist-packages (from bagpipes) (5.3.4)\n","Requirement already satisfied: matplotlib>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from bagpipes) (3.7.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bagpipes) (1.11.4)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from bagpipes) (1.0.8)\n","Collecting spectres (from bagpipes)\n","  Downloading spectres-2.2.0-py2.py3-none-any.whl (19 kB)\n","Collecting nautilus-sampler>=1.0.2 (from bagpipes)\n","  Downloading nautilus_sampler-1.0.2-py2.py3-none-any.whl (32 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->bagpipes) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->bagpipes) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->bagpipes) (4.50.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->bagpipes) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->bagpipes) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->bagpipes) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->bagpipes) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->bagpipes) (2.8.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nautilus-sampler>=1.0.2->bagpipes) (1.2.2)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from nautilus-sampler>=1.0.2->bagpipes) (3.4.0)\n","Requirement already satisfied: pyerfa>=2.0 in /usr/local/lib/python3.10/dist-packages (from astropy->bagpipes) (2.0.1.1)\n","Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from astropy->bagpipes) (6.0.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->bagpipes) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2.2->bagpipes) (1.16.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nautilus-sampler>=1.0.2->bagpipes) (1.3.2)\n","Installing collected packages: pymultinest, spectres, nautilus-sampler, corner, bagpipes\n","Successfully installed bagpipes-1.1.1 corner-2.2.2 nautilus-sampler-1.0.2 pymultinest-2.12 spectres-2.2.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["google.colab.output.setIframeHeight('100px');"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"7F9ZOvYN_2__","executionInfo":{"status":"ok","timestamp":1712067337028,"user_tz":-60,"elapsed":21122,"user":{"displayName":"Adam Carnall","userId":"09223017103187743113"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"57f8e988-0cb8-489c-c5e0-c96e3f102d17"},"source":["# Ignore the MultiNest errors\n","\n","import numpy as np\n","import bagpipes as pipes\n","import time\n","import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n","import tensorflow as tf\n","import tensorflow.experimental.numpy as tnp\n","\n","gpu = tf.config.list_logical_devices(device_type=\"GPU\")[0]\n","cpu = tf.config.list_logical_devices(device_type=\"CPU\")[0]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BAGPIPES: Generating IGM absorption table.\n","Bagpipes: Latex distribution not found, plots may look strange.\n","Bagpipes: PyMultiNest import failed, fitting will use the Nautilus sampler instead.\n"]}]},{"cell_type":"markdown","metadata":{"id":"YoXp-xRQELHc"},"source":["The code below generates some random star-formation and chemical enrichment histories, then collapses the BC03 stellar grid into a 1D spectrum with them using a tensorflow function.\n","\n","The process is repeated on a CPU and a GPU. Play around with the number of models and number of wavelength points. How does the time taken per model scale with these two quantities on the CPU and GPU? What regime might it be worth using the GPU in? Remember, it's usually fairly easy to get hold of multiple CPUs at once, whereas getting access to lots of GPUs at once might be a bit more difficult."]},{"cell_type":"code","metadata":{"id":"4dG9gViG3My6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712067340856,"user_tz":-60,"elapsed":3850,"user":{"displayName":"Adam Carnall","userId":"09223017103187743113"}},"outputId":"5da7da06-d355-46ec-dc69-5ae7abd5a612"},"source":["# Set how many models to generate and how many wavelength points per spectrum\n","n_models = 1000\n","n_wav_points = 1000\n","\n","print(\"\\nNumber of wavelength grid points:\", n_wav_points)\n","print(\"Making\", n_models, \"models\\n\")\n","\n","# Make wavelength sampling\n","wavs = np.logspace(1, 8, n_wav_points)\n","\n","# Initialise bagpipes stellar model to get access to the BC03 stellar grid\n","stellar_model = pipes.models.stellar(wavs)\n","\n","\n","@tf.function(experimental_compile=True)\n","def spectrum_tf(sfh_ceh, grid):\n","    \"\"\" tensorflow function to collapse stellar grid and SFH into a spectrum \"\"\"\n","    spectrum = tf.math.reduce_sum(tf.math.reduce_sum(grid*sfh_ceh, axis=2), axis=1)\n","\n","    return spectrum\n","\n","\n","# Make some random star-formation and chemical enrichment histories\n","sfh_grid = tf.constant(np.random.randn(n_models, 7, 42) + 10.)\n","\n","# Pull the BC03 stellar model grid out of bagpipes\n","stellar_grid = tf.constant(stellar_model.grid)\n","print(\"Stellar grid dimensions (wavelength, metallicity, age)\", stellar_grid.shape, \"\\n\")\n","\n","# Time grid making on cpu\n","time0 = time.time()\n","\n","with tf.device(cpu):\n","    for i in range(n_models):\n","        spectrum_tf(sfh_grid[i, :, :], stellar_grid)\n","\n","time_stellar_tf_cpu = (time.time() - time0)/n_models\n","print(\"Average time cpu:\", \"%.6f\" % time_stellar_tf_cpu, \"seconds.\")\n","\n","\n","# Time grid making on gpu\n","time0 = time.time()\n","\n","with tf.device(gpu):\n","    for i in range(n_models):\n","        spectrum_tf(sfh_grid[i, :, :], stellar_grid)\n","\n","time_stellar_tf_gpu = (time.time() - time0)/n_models\n","print(\"Average time gpu:\", \"%.6f\" % time_stellar_tf_gpu, \"seconds.\")\n","print(\"gpu speed =\", \"%.3f\" % (time_stellar_tf_cpu/time_stellar_tf_gpu), \"x cpu speed\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Number of wavelength grid points: 1000\n","Making 1000 models\n","\n","Stellar grid dimensions (wavelength, metallicity, age) (1000, 7, 42) \n","\n","Average time cpu: 0.001921 seconds.\n","Average time gpu: 0.001691 seconds.\n","gpu speed = 1.136 x cpu speed\n"]}]},{"cell_type":"markdown","metadata":{"id":"aODFHIXLGGHa"},"source":["Of course, in the above example, each model is generated sequentially, as is necessary if you're using a sampling routine that tells you which models it wants generated. What about if we can generate all n_models at once, as we would, for example, with a grid-based code."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ffnhHW8BAk-S","executionInfo":{"status":"ok","timestamp":1712067342932,"user_tz":-60,"elapsed":2087,"user":{"displayName":"Adam Carnall","userId":"09223017103187743113"}},"outputId":"09c0c331-c9d2-44f2-c55e-da6b45da9b20"},"source":["# Set how many models to generate and how many wavelength points per spectrum\n","n_models = 1000\n","n_wav_points = 1000\n","\n","print(\"\\nNumber of wavelength grid points:\", n_wav_points)\n","print(\"Making\", n_models, \"models\\n\")\n","\n","# Make wavelength sampling\n","wavs = np.logspace(1, 8, n_wav_points)\n","\n","# Initialise bagpipes stellar model to get access to the BC03 stellar grid\n","stellar_model = pipes.models.stellar(wavs)\n","\n","\n","@tf.function(experimental_compile=True)\n","def spectrum_grid_tf(sfh_ceh, grid):\n","    \"\"\" Collapse stellar grid and N x SFH into N x spectra \"\"\"\n","    spectrum_grid = tf.math.reduce_sum(tf.math.reduce_sum(grid*sfh_ceh, axis=2), axis=1)\n","\n","    return spectrum_grid\n","\n","\n","# Make some random star-formation and chemical enrichment histories\n","sfh_grid = tf.constant(np.random.randn(1, 7, 42, n_models) + 10.)\n","\n","# Pull the BC03 stellar model grid out of bagpipes\n","stellar_grid = np.expand_dims(tf.constant(stellar_model.grid), axis=-1)\n","\n","# Time grid making on cpu\n","time0 = time.time()\n","\n","with tf.device(cpu):\n","    spectrum_grid = spectrum_grid_tf(sfh_grid, stellar_grid)\n","\n","time_stellar_tf_cpu = (time.time() - time0)/n_models\n","\n","print(\"Average time cpu:\", \"%.6f\" % time_stellar_tf_cpu, \"seconds.\")\n","\n","\n","# Time grid making on gpu\n","time0 = time.time()\n","\n","with tf.device(gpu):\n","    spectrum_grid = spectrum_grid_tf(sfh_grid, stellar_grid)\n","\n","time_stellar_tf_gpu = (time.time() - time0)/n_models\n","\n","print(\"Average time gpu:\", \"%.6f\" % time_stellar_tf_gpu, \"seconds.\")\n","print(\"gpu speed =\", \"%.3f\" % (time_stellar_tf_cpu/time_stellar_tf_gpu), \"x cpu speed\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Number of wavelength grid points: 1000\n","Making 1000 models\n","\n","Average time cpu: 0.002117 seconds.\n","Average time gpu: 0.000173 seconds.\n","gpu speed = 12.272 x cpu speed\n"]}]}]}